{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4e8e87-5368-4d23-8de9-9ef8063e68b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_DATASET = 'XXX'\n",
    "PRETRAINED_MODEL = 'raquelsilveira/legalbertpt_fp' #'neuralmind/bert-base-portuguese-cased'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4596b88",
   "metadata": {},
   "source": [
    "## Leitura dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b55a4a-c263-4d8d-b0c6-3bf77ac3d355",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_data = pd.read_csv(PATH_DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373c94f5-437b-4245-9804-28c2c7556b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n1 = df_data.n1.unique()\n",
    "for n in n1:\n",
    "    print(f'{n} - {df_data[df_data.n1 == n].label.nunique()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19881b52-d39f-49c2-978a-5040ac9aab47",
   "metadata": {},
   "source": [
    "## Encode Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3884fbf-2327-4b47-832a-2d49a20c2250",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "\n",
    "from datetime import datetime\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "path_encode_saida = f'/input/'\n",
    "\n",
    "from preprocessing.encoding_bert import encode_bert\n",
    "\n",
    "begin = datetime.now()\n",
    "print(f'Inicio: {begin}')\n",
    "\n",
    "df_data = pd.read_csv(PATH_DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae497b8b-bcef-438a-80cd-8f65010c90c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lecm02/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(PRETRAINED_MODEL, do_lower_case=False, use_fast = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "24dce76b-a17c-45ee-85e5-146fe0d08668",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/lecm02/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2302: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "input_token_size = 512\n",
    "\n",
    "# Encode\n",
    "encoded_data = tokenizer.batch_encode_plus(\n",
    "    df_data.texto_tratado.values,\n",
    "    add_special_tokens=True,\n",
    "    return_attention_mask=True,\n",
    "    pad_to_max_length=True,\n",
    "    max_length=input_token_size,\n",
    "    return_tensors='pt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8884ad31-7f1f-465b-a1cc-af0cead66f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_ids = df_data['id_processo']\n",
    "documentos_id = df_data['id_processo_documento']\n",
    "input_ids = encoded_data['input_ids']\n",
    "attention_masks = encoded_data['attention_mask']\n",
    "\n",
    "headers_input = [f'input_{i}' for i in range(input_ids.shape[1])]\n",
    "input_savein = os.path.join(path_encode_saida, f'input_ids.csv')\n",
    "\n",
    "df_input_ids = pd.DataFrame(np.array(input_ids), columns=headers_input)\n",
    "df_input_ids = pd.concat([process_ids, documentos_id, df_input_ids], axis=1)\n",
    "df_input_ids.to_csv(input_savein, index=False)\n",
    "\n",
    "headers_mask = [f'att_mask_{i}' for i in range(attention_masks.shape[1])]\n",
    "att_savein = os.path.join(path_encode_saida, f'attention_masks.csv')\n",
    "\n",
    "df_attention_masks = pd.DataFrame(np.array(attention_masks), columns=headers_mask)\n",
    "df_attention_masks = pd.concat([process_ids, documentos_id, df_attention_masks], axis=1)\n",
    "df_attention_masks.to_csv(att_savein, index=False)\n",
    "\n",
    "end = datetime.now()\n",
    "print(f'Final: {end}')\n",
    "print(f'Tempo total: {end - begin}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57ffa5f-5633-41ed-a5d3-7338a09ce801",
   "metadata": {},
   "source": [
    "## Run BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3c9686-a291-423c-8a7d-bf45f95addf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def get_data_encodes(path_encode):\n",
    "    path_encode_input = os.path.join(path_encode, 'input_ids.csv')\n",
    "    path_encode_mask = os.path.join(path_encode, 'attention_masks.csv')\n",
    "\n",
    "    df_input = pd.read_csv(path_encode_input)\n",
    "    array_inputs = list(df_input.drop(columns=['id_processo', 'id_processo_documento']).values)\n",
    "    df_input['input_ids'] = array_inputs\n",
    "    df_input = df_input[['id_processo', 'id_processo_documento', 'input_ids']]\n",
    "    df_input = df_input.rename(columns={'id_processo': 'processo_id',\n",
    "                                        'id_processo_documento': 'documento_id'})\n",
    "\n",
    "    df_mask = pd.read_csv(path_encode_mask)\n",
    "    array_mask = list(df_mask.drop(columns=['id_processo', 'id_processo_documento']).values)\n",
    "    df_mask['attention_masks'] = array_mask\n",
    "    df_mask = df_mask[['id_processo', 'id_processo_documento', 'attention_masks']]\n",
    "    df_mask = df_mask.rename(columns={'id_processo': 'processo_id',\n",
    "                                      'id_processo_documento': 'documento_id'})\n",
    "\n",
    "    df_merge = pd.merge(df_input, df_mask, how='inner', on=['processo_id', 'documento_id'])\n",
    "\n",
    "    size = len(df_merge.iloc[0]['input_ids'])\n",
    "\n",
    "    return df_merge, size\n",
    "\n",
    "\n",
    "def get_data(path_dataset, path_encode, percent_treino=0.8):\n",
    "\n",
    "  df_data = pd.read_csv(path_dataset, usecols=['documento_id', 'processo_id', 'assunto_id', 'label'])\n",
    "\n",
    "  df_data.rename(columns={'cd_assunto_trf' : 'assunto_id',\n",
    "                          'id_processo_documento': 'documento_id',\n",
    "                          'id_processo': 'processo_id'},\n",
    "                 inplace=True)\n",
    "  \n",
    "  print('Tamanho do dataset:', len(df_data))\n",
    "\n",
    "  \n",
    "  df_encode, size = get_data_encodes(path_encode)\n",
    "  df_data = pd.merge(df_data, df_encode, how='inner', on=['processo_id', 'documento_id'])\n",
    "  \n",
    "  df_data = df_data[df_data.groupby(['label'])['documento_id'].transform('nunique') > 10]\n",
    "\n",
    "  print(len(df_data))\n",
    "\n",
    "  df_data_treino, df_data_teste, _, _ = train_test_split(df_data, df_data['label'],\n",
    "                                                        test_size=1-percent_treino, stratify=df_data['label'],\n",
    "                                                        random_state = 0)\n",
    "\n",
    "  df_data_treino['split'] = ['train'] * len(df_data_treino)\n",
    "  df_data_teste['split'] = ['test'] * len(df_data_teste)\n",
    "  df_concat = pd.concat([df_data_treino, df_data_teste])\n",
    "\n",
    "  print('Tamanho dataset (df_concat):', len(df_concat))\n",
    "  return df_concat\n",
    "\n",
    "def wrapper_tensor_data_bert(data):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    processo_ids = []\n",
    "    labels = []\n",
    "\n",
    "    for _, row in data.iterrows():\n",
    "      \n",
    "      input_ids.append(list(row['input_ids']))\n",
    "      attention_masks.append(list(row['attention_masks']))\n",
    "      processo_ids.append(row['processo_id'])\n",
    "      labels.append(row['id_label'])\n",
    "\n",
    "    input_ids = torch.tensor(input_ids)\n",
    "    attention_masks = torch.tensor(attention_masks)\n",
    "    labels = torch.tensor(labels)\n",
    "    processo_ids = torch.tensor(processo_ids)\n",
    "\n",
    "    print('labels', labels)\n",
    "    return TensorDataset(input_ids, attention_masks, labels, processo_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1a7e8129-4bcc-453d-89fc-a8f395e4fb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_classificador(x_data, val_size, train_size, batch_size):\n",
    "\n",
    "  x_data['documento_id'] = x_data['documento_id'].astype(int)\n",
    "\n",
    "  x_data_train, x_data_test = x_data[x_data.split == 'train'], x_data[x_data.split == 'test']\n",
    "  y_test = x_data_test['id_label']\n",
    "\n",
    "  percent_val = val_size / (val_size + train_size)\n",
    "\n",
    "  x_data_train, x_data_val, y_train, y_val = train_test_split(x_data_train, x_data_train['id_label'],\n",
    "                                                    test_size=percent_val, stratify=x_data_train['id_label'],\n",
    "                                                    random_state = 0)\n",
    "\n",
    "\n",
    "  print('train:', len(x_data_train))\n",
    "  print('teste:', len(x_data_test))\n",
    "  print('val:', len(x_data_val))\n",
    "  dataset_train = wrapper_tensor_data_bert(x_data_train)\n",
    "  dataset_val = wrapper_tensor_data_bert(x_data_val)\n",
    "  dataset_test = wrapper_tensor_data_bert(x_data_test)\n",
    "\n",
    "  return dataset_train, dataset_val, dataset_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef018a71-0fc4-4866-a7f0-382f750c2df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_classifier(path_dataset, path_encode):\n",
    "\n",
    "    df_data = get_data(path_dataset, path_encode)\n",
    "    print('Tamanho dataset:', len(df_data))\n",
    "\n",
    "    num_class = df_data['label'].nunique()\n",
    "    print('Número de classes:', num_class)\n",
    "\n",
    "    labels = list(df_data['label'].unique())\n",
    "    dict_label = {}\n",
    "    for id, value  in enumerate(labels):\n",
    "      dict_label[value] = id\n",
    "\n",
    "    df_data['id_label'] = df_data['label'].replace(dict_label)\n",
    "\n",
    "    dataset_train, dataset_val, dataset_test = get_data_classificador(df_data, percen_val, percent_treino, batch_size)\n",
    "\n",
    "    dataloader_train = DataLoader(dataset_train,\n",
    "                              sampler=RandomSampler(dataset_train),\n",
    "                              batch_size=batch_size)\n",
    "\n",
    "    dataloader_val = DataLoader(dataset_val,\n",
    "                                sampler=SequentialSampler(dataset_val),\n",
    "                                batch_size=batch_size)\n",
    "\n",
    "    dataloader_test = DataLoader(dataset_test,\n",
    "                                sampler=SequentialSampler(dataset_test),\n",
    "                                batch_size=batch_size)\n",
    "\n",
    "    return dataloader_train, dataloader_val, dataloader_test, dict_label, num_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a775a6fd-9b36-4563-8e6f-18f9886dab53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer, AutoModelForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "\n",
    "def get_model(modelo_id, num_class, dataloader_train):\n",
    "\n",
    "  model = AutoModelForSequenceClassification.from_pretrained(modelo_id, num_labels=num_class, output_attentions=False, output_hidden_states=False, id2label=label_dict)\n",
    "\n",
    "  optimizer = AdamW(model.parameters(), lr=1e-5, eps=1e-8)\n",
    "\n",
    "  scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                            num_warmup_steps=0,\n",
    "                                            num_training_steps=len(dataloader_train)*epochs)\n",
    "\n",
    "  return model, optimizer, scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e508e314-1097-488f-8f5f-7348a7f591bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d5fbf17d-8964-46b4-84bb-8fd9060120fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataloader_test, model):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    loss_test_total = 0\n",
    "    predictions, true_test = [], []\n",
    "\n",
    "    processos = []\n",
    "\n",
    "    for batch in dataloader_test:\n",
    "\n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "\n",
    "        processos.extend(batch[3].cpu().numpy())\n",
    "\n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2],\n",
    "                 }\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "        loss_test_total += loss.item()\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = inputs['labels'].cpu().numpy()\n",
    "        predictions.append(logits)\n",
    "        true_test.append(label_ids)\n",
    "\n",
    "    loss_test_avg = loss_test_total/len(dataloader_test)\n",
    "\n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    true_test = np.concatenate(true_test, axis=0)\n",
    "\n",
    "    return loss_test_avg, predictions, true_test, processos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "97235415-2fcf-4377-8737-17643b622e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
    "\n",
    "def f1_score_func(preds, labels, metric):\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return f1_score(labels_flat, preds_flat, average=metric)\n",
    "\n",
    "def f1_score_func_average(preds, labels, average_f1):\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return f1_score(labels_flat, preds_flat, average=average_f1)\n",
    "\n",
    "def accuracy_score_func(preds, labels):\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return metrics.accuracy_score(labels_flat, preds_flat)\n",
    "\n",
    "def classification_report_func(preds, labels):\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    report = metrics.classification_report(labels_flat,preds_flat)\n",
    "    print(report)\n",
    "\n",
    "def confusion_matrix_class(labels, preds):\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return confusion_matrix(labels_flat,preds_flat)\n",
    "\n",
    "def accuracy_per_class(preds, labels):\n",
    "    label_dict_inverse = {v: k for k, v in label_dict.items()}\n",
    "\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "\n",
    "    for label in np.unique(labels_flat):\n",
    "        y_preds = preds_flat[labels_flat==label]\n",
    "        y_true = labels_flat[labels_flat==label]\n",
    "        print(f'Class: {label_dict_inverse[label]}')\n",
    "        print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b690e31a-52d8-4a5c-b1ed-7a3115ed1671",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_train(model, optimizer, scheduler, dataloader_train, dataloader_val):\n",
    "\n",
    "  model.to(device)\n",
    "\n",
    "  history = {\n",
    "      'train': {\n",
    "        'f1_weighted': [], 'f1_micro': [], 'f1_macro': [], 'acc': [], 'loss': []\n",
    "      },\n",
    "      'val': {\n",
    "        'f1_weighted': [], 'f1_micro': [], 'f1_macro': [], 'acc': [], 'loss': []\n",
    "      }\n",
    "  }\n",
    "\n",
    "  best_model = None\n",
    "  best_metric = -1\n",
    "\n",
    "  early_stop_count = 0\n",
    "\n",
    "  for epoch in tqdm.tqdm(range(1, epochs+1)):\n",
    "\n",
    "      if early_stop_count >= early_stop:\n",
    "          print(\"Early stop!\")\n",
    "          break\n",
    "\n",
    "      model.train()\n",
    "\n",
    "      loss_train_total = 0\n",
    "\n",
    "      for batch in dataloader_train:\n",
    "\n",
    "          model.zero_grad()\n",
    "\n",
    "          batch = tuple(b.to(device) for b in batch)\n",
    "\n",
    "          inputs = {'input_ids':      batch[0],\n",
    "                    'attention_mask': batch[1],\n",
    "                    'labels':         batch[2],\n",
    "                  }\n",
    "                  \n",
    "          outputs = model(**inputs)\n",
    "\n",
    "          loss = outputs[0]\n",
    "          loss_train_total += loss.item()\n",
    "\n",
    "          loss.backward()\n",
    "\n",
    "          torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "          optimizer.step()\n",
    "          scheduler.step()\n",
    "\n",
    "      torch.cuda.empty_cache()\n",
    "      \n",
    "      tqdm.tqdm.write(f'\\nEpoch {epoch}')\n",
    "\n",
    "      loss_train_avg = loss_train_total/len(dataloader_train)\n",
    "\n",
    "      train_loss, predictions_train, true_train, _ = evaluate(dataloader_train, model)\n",
    "      val_loss, predictions_val, true_val, _ = evaluate(dataloader_val, model)\n",
    "\n",
    "      tqdm.tqdm.write(f'Train loss: {train_loss}, Val loss: {val_loss}')\n",
    "\n",
    "      acc_train = accuracy_score_func(predictions_train, true_train)\n",
    "      f1_micro_train = f1_score_func(predictions_train, true_train, 'micro')\n",
    "      f1_macro_train = f1_score_func(predictions_train, true_train, 'macro')\n",
    "      f1_weighted_train = f1_score_func(predictions_train, true_train, 'weighted')\n",
    "\n",
    "      acc_val = accuracy_score_func(predictions_val, true_val)\n",
    "      f1_micro_val = f1_score_func(predictions_val, true_val, 'micro')\n",
    "      f1_macro_val = f1_score_func(predictions_val, true_val, 'macro')\n",
    "      f1_weighted_val = f1_score_func(predictions_val, true_val, 'weighted')\n",
    "\n",
    "      history['train']['acc'].append(acc_train)\n",
    "      history['train']['loss'].append(train_loss)\n",
    "      history['train']['f1_macro'].append(f1_micro_train)\n",
    "      history['train']['f1_micro'].append(f1_macro_train)\n",
    "      history['train']['f1_weighted'].append(f1_weighted_train)\n",
    "\n",
    "      history['val']['acc'].append(acc_val)\n",
    "      history['val']['loss'].append(val_loss)\n",
    "      history['val']['f1_macro'].append(f1_micro_val)\n",
    "      history['val']['f1_micro'].append(f1_macro_val)\n",
    "      history['val']['f1_weighted'].append(f1_weighted_val)\n",
    "\n",
    "\n",
    "      early_stop_count += 1\n",
    "      if best_model is None or f1_weighted_val > best_metric:\n",
    "          print(f'best model:{epoch} : {f1_weighted_val} - {best_metric}')\n",
    "          best_metric = f1_weighted_val\n",
    "          best_model = copy.copy(model)\n",
    "          early_stop_count = 0\n",
    "\n",
    "      torch.cuda.empty_cache()\n",
    "\n",
    "  best_model.config.id2label = label_dict\n",
    "  best_model.config.label2id = {label_dict[d] : d for d in label_dict}\n",
    "\n",
    "  best_model.save_pretrained(f'{path_saida}/modelo_classificacao_bert/')\n",
    "\n",
    "  return best_model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c1ebdc-acdc-48df-be73-f29a75823fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics_train(history):\n",
    "  plt.figure(figsize=(12,10))\n",
    "\n",
    "  epochs = list(range(len(history['train']['loss'])))\n",
    "\n",
    "  subplots = 1\n",
    "  metrics = ['loss', 'acc', 'f1_macro', 'f1_micro', 'f1_weighted']\n",
    "\n",
    "  for m in metrics:\n",
    "\n",
    "    plt.subplot(3,2,subplots)\n",
    "    plt.plot(epochs, history['train'][m], '.-', label='train')\n",
    "    plt.plot(epochs, history['val'][m], '.-', label='val')\n",
    "    plt.ylabel(m)\n",
    "\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "\n",
    "    subplots += 1\n",
    "    plt.tight_layout()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc089bd1-2f41-4b36-be12-fb62bccb1d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import copy\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "\n",
    "modelo_id = PRETRAINED_MODEL\n",
    "\n",
    "path_saida = '/bracis_2025_bertimbau/'\n",
    "path_encode = '/input/'\n",
    "\n",
    "percent_treino = 0.80\n",
    "percen_val = 0.05\n",
    "batch_size = 4\n",
    "epochs = 20\n",
    "early_stop = 5\n",
    "balanceamento = False\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "dataloader_train, dataloader_val, dataloader_test, dict_label, num_class = get_data_classifier(PATH_DATASET, path_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a03a58b-395e-477c-8e24-d2fc012ddb50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#id2label\n",
    "label_dict = {v: k for k, v in dict_label.items()}\n",
    "\n",
    "model, optimizer, scheduler = get_model(modelo_id, num_class, dataloader_train)\n",
    "\n",
    "best_model, history = run_train(model, optimizer, scheduler, dataloader_train, dataloader_val)\n",
    "get_metrics_train(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef89e2f9-9bc0-4339-9490-b95f3ac68e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, predictions, true_test, processos = evaluate(dataloader_test, best_model)\n",
    "\n",
    "classification_report(true_test, predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
